# Context-aware-Retrieval-Answering-with-Quality

场景是用户输入《长安的荔枝》相关问题，通过CoT和RAG，基于deepseek v3进行推理检索答案，根据最终答案与事先准备的答案的语义相似度进行评估

#### 文本结构
```
├── QAdata.json               # 主数据集：问题、答案、类型、证据段落
├── redis_top5.py            # 检索模块：返回 top-k 相关段落
├── build_prompt.py          # 构建带推理结构的 Prompt
├── run_eval.py              # 主运行脚本，调用模型并保存结果
├── output_full.json         # 保存完整的问答过程与模型输出
├── output_similarity.json   # 保存问题编号与余弦相似度得分
```
### 系统特点
🚀 检索增强（RAG）
基于 Redis 向量索引，对用户问题进行语义检索，返回最相关的段落作为上下文支撑。
🧩 CoT 推理链
在 Prompt 中引导模型进行逐步推理，模拟“人类思考”流程，避免直接输出“拍脑袋式”的答案。
📌 明确答案标识
使用统一格式 ### 最终答案: 标注答案，方便系统提取与评估。
📊 语义相似度评估
使用 BAAI/bge-m3 进行模型输出与标准答案的向量编码，并计算余弦相似度以量化回答质量。
📝 自动输出归档
所有问题的完整对话过程与评估结果自动存储为结构化文档，便于后续分析与模型调优。

### 数据集介绍：《长安的荔枝》问答集
本项目数据构建自小说文本《长安的荔枝》，手工设计了一批结构化问答样本，支持模型在文档级语义理解与推理能力上的评估。

#### 数据结构
| 字段名                   | 描述                 |
| --------------------- | ------------------ |
| `question`            | 用户提出的问题，聚焦细节与因果    |
| `answer`              | 基于文档内容人工撰写的参考答案    |
| `answer_type`         | 答案类型，如“事实型”、“解释型”等 |
| `evidence_paragraphs` | 参考答案所依赖的段落编号       |
| `para_id:text`        | 原文段落编号及内容，用于向量检索   |
