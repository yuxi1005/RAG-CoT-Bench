# embedding_gen.py
# ç”Ÿæˆã€Šé•¿å®‰çš„è”æã€‹æ¯æ®µçš„BGE-M3å‘é‡ï¼Œå¹¶ä¿å­˜ä¸ºJSON

from sentence_transformers import SentenceTransformer
import json

# === é…ç½® ===
MODEL_NAME = "BAAI/bge-m3"
INPUT_FILE = "data/ChangAnLiZhi.txt"  # æ¯è¡Œæ ¼å¼ï¼š[æ®µè½ç¼–å·]æ­£æ–‡å†…å®¹
OUTPUT_FILE = "data/ChangAnLiZhi_with_embeddings.json"

# === åŠ è½½æ¨¡å‹ ===
model = SentenceTransformer(MODEL_NAME)
print("âœ… BGE-M3 æ¨¡å‹åŠ è½½å®Œæˆ")

# === è¯»å–æ®µè½æ–‡æœ¬ ===
paragraphs = []
with open(INPUT_FILE, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line or not line.startswith("[æ®µè½"):
            continue
        try:
            idx_end = line.index("]")
            chunk_id = int(line[3:idx_end])
            text = line[idx_end + 1:].strip()
            paragraphs.append({"chunk_id": chunk_id, "text": text})
        except:
            print(f"âŒ è·³è¿‡å¼‚å¸¸è¡Œ: {line}")

print(f"ğŸ“š å…±è¯»å–åˆ° {len(paragraphs)} ä¸ªæ®µè½")

# === æå–æ–‡æœ¬å¹¶ç”Ÿæˆå‘é‡ ===
texts = [p["text"] for p in paragraphs]
embeddings = model.encode(texts, normalize_embeddings=True)

# === åˆå¹¶ç»“æœå¹¶å†™å…¥ JSON ===
for i in range(len(paragraphs)):
    paragraphs[i]["embedding"] = embeddings[i].tolist()

with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    json.dump(paragraphs, f, ensure_ascii=False, indent=2)

print(f"âœ… å‘é‡å†™å…¥æˆåŠŸï¼Œè¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_FILE}")
